<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>"Part 1: Where Multimodal Reasoning Actually Lives" - Vedaang Chopra</title>
    <link rel="stylesheet" href="https://vedaangchopra.live/theme/css/style.css" />
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <a href="https://vedaangchopra.live/" class="profile-brand">
                    <img src="https://vedaangchopra.live/images/profile.png" alt="Profile" class="profile-circle">
                </a>
                <a href="https://vedaangchopra.live/" class="brand">Home</a>
                <a href="https://vedaangchopra.live/projects.html">Projects</a>
                <a href="/resume.html">Resume</a>
                <a href="/blog.html">Writing</a>
                <a href="/uses.html">Uses</a>
                <button id="theme-toggle" aria-label="Toggle Theme">
                    <span class="icon">‚òÄ</span>
                </button>
            </nav>
        </header>

        <main>
<article>
    <header>
        <h1>"Part 1: Where Multimodal Reasoning Actually Lives"</h1>
        <div class="meta">
            <span class="date">2024-10-24</span>
        </div>
    </header>
    
    <div class="content">
        <p><strong>Part 1 of a 4-part series on Vision-Language Model design.</strong><br>
‚Üê Previous | <a href="/blog/molmo-part-2">Next ‚Üí</a></p>
<hr>
<h1>Where Multimodal Reasoning Actually Lives</h1>
<h2>Why MOLMO Is Worth Studying</h2>
<p>Most recent discussions around Vision-Language Models (VLMs) revolve around benchmarks, scale, or whether a model is "open" in name. MOLMO is interesting for a different reason. It is one of the few recent VLMs that can be treated as a <strong>complete research artifact</strong>‚Äîone where data construction, architectural decisions, training choices, and evaluation all form a coherent story.</p>
<p>This article is not a leaderboard-driven summary of MOLMO. Instead, it uses MOLMO as a <strong>lens to reason about VLM design itself</strong>: where multimodal reasoning actually happens, why many VLMs fail silently, and how architectural decisions upstream of the language model determine what kind of intelligence is even possible downstream.</p>
<p>The central argument is simple but often overlooked:</p>
<blockquote>
<p>Multimodal reasoning does not emerge inside the LLM by default. It emerges only if the architecture preserves, aligns, and exposes visual information in a form the LLM can actually reason over.</p>
</blockquote>
<p>MOLMO is valuable because it makes these constraints explicit‚Äîand largely gets them right.</p>
<hr>
<h2>The Core VLM Abstraction</h2>
<p>At a high level, most VLMs look deceptively similar: an image encoder, a connector, and a language model. This simplicity hides a deeper question that determines success or failure:</p>
<p><strong>Where, exactly, does multimodal reasoning occur?</strong></p>
<p>Not in the vision encoder alone. Not magically inside the LLM. And not in the connector by virtue of existing. Multimodal reasoning only emerges if three conditions are met:</p>
<ol>
<li>
<p><strong>Visual information survives preprocessing</strong><br>
   If critical spatial or fine-grained details are destroyed before encoding, no amount of downstream reasoning can recover them.</p>
</li>
<li>
<p><strong>Visual tokens are aligned, not merely projected</strong><br>
   The connector must preserve structure, locality, and layout‚Äînot just match embedding dimensions.</p>
</li>
<li>
<p><strong>The decoder has unrestricted access to vision during generation</strong><br>
   Vision must act as persistent context, not a compressed hint.</p>
</li>
</ol>
<p>Most VLM failures trace back to violations of one or more of these constraints, often invisibly.</p>
<h3>A Minimal VLM Abstraction</h3>
<p>Conceptually, almost all VLMs can be reduced to the following pipeline:</p>
<div class="highlight"><pre><span></span><code><span class="n">flowchart</span><span class="w"> </span><span class="n">LR</span>
<span class="w">    </span><span class="n">I</span><span class="p">[</span><span class="n">Image</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">VE</span><span class="p">[</span><span class="n">Vision</span><span class="w"> </span><span class="n">Encoder</span><span class="p">]</span>
<span class="w">    </span><span class="n">VE</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">Vision</span><span class="o">-</span><span class="n">Language</span><span class="w"> </span><span class="n">Connector</span><span class="p">]</span>
<span class="w">    </span><span class="n">C</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">LLM</span><span class="p">[</span><span class="n">Language</span><span class="w"> </span><span class="n">Model</span><span class="w"> </span><span class="n">Decoder</span><span class="p">]</span>
<span class="w">    </span><span class="n">T</span><span class="p">[</span><span class="n">Text</span><span class="w"> </span><span class="n">Prompt</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">LLM</span>
</code></pre></div>

<p>This diagram is misleadingly clean. The real complexity lies in what happens <em>inside</em> each arrow.</p>
<ul>
<li>The <strong>Image ‚Üí Vision Encoder</strong> step determines what information is even representable.</li>
<li>The <strong>Encoder ‚Üí Connector</strong> step determines what structure survives compression.</li>
<li>The <strong>Connector ‚Üí LLM</strong> step determines whether vision is accessible during reasoning or merely appended as context.</li>
</ul>
<p>MOLMO's architecture follows this standard design‚Äîconnecting a vision encoder to a language model‚Äîas shown in Figure 2 from the paper:</p>
<p><img alt="MOLMO follows the simple and standard design of connecting a vision encoder and a language model." src="/images/molmo_inference_flow.png"></p>
<p><em>Figure 2: MOLMO's end-to-end inference flow. An image is tiled into crops, encoded, and fused with tokenized text. The LLM outputs an answer with optional pointing coordinates.</em></p>
<hr>
<h2>Where Multimodal Reasoning Fails</h2>
<p>From a research perspective, the most important insight is this:</p>
<blockquote>
<p>The LLM cannot reason over what it cannot attend to, and it cannot attend to what the architecture has already discarded.</p>
</blockquote>
<p>Consider what happens in a typical VLM pipeline:</p>
<ul>
<li>A rectangular image is resized to a fixed square resolution (e.g., 224√ó224 or 336√ó336).</li>
<li>Fine details (text, symbols, small objects) are blurred or aliased.</li>
<li>Spatial relationships are distorted.</li>
<li>The vision encoder produces tokens that are already missing critical information.</li>
</ul>
<p>At this point, <strong>the LLM has already lost</strong>, regardless of how powerful it is.</p>
<p>MOLMO's contribution is not that it invents new components, but that it treats these transitions as first-class design problems rather than implementation details. In the parts that follow, we will progressively zoom in on how MOLMO addresses each of these failure modes‚Äîstarting with the most underestimated part of VLMs: how images are prepared <em>before</em> any transformer ever sees them.</p>
<hr>
<p><strong>Part 1 of a 4-part series on Vision-Language Model design.</strong><br>
‚Üê Previous | <a href="/blog/molmo-part-2">Next ‚Üí</a></p>
    </div>
</article>
        </main>

        <footer>
            <div class="footer-content">
                <div class="footer-icons">
                    <a href="https://github.com/Vedaang-Chopra" target="_blank" class="footer-icon-btn" aria-label="GitHub">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    </a>
                    <a href="https://linkedin.com/in/vedaang-chopra/" target="_blank" class="footer-icon-btn" aria-label="LinkedIn">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg>
                    </a>
                    <a href="mailto:vedaangchopra1009@gmail.com" class="footer-icon-btn" aria-label="Email">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg>
                    </a>
                </div>
                <div class="footer-links">
                    <p>&copy; 2026 Vedaang Chopra</p>
                </div>
            </div>
        </footer>
    </div>

    <script>
        const toggleBtn = document.getElementById('theme-toggle');
        const body = document.body;
        const icon = toggleBtn.querySelector('.icon');

        // Theme Definitions
        const themes = ['', 'mint-theme', 'dark-theme', 'sepia-theme'];
        const icons = ['‚òÄ', 'üåø', 'üåô', '‚òï'];

        // Load saved theme
        let currentThemeIndex = 0;
        const savedTheme = localStorage.getItem('theme');
        
        if (savedTheme) {
            const savedIndex = themes.indexOf(savedTheme);
            if (savedIndex !== -1) {
                currentThemeIndex = savedIndex;
                if (themes[currentThemeIndex]) {
                    body.classList.add(themes[currentThemeIndex]);
                }
                icon.textContent = icons[currentThemeIndex];
            }
        }

        toggleBtn.addEventListener('click', () => {
            // Remove current theme class if it exists
            if (themes[currentThemeIndex]) {
                body.classList.remove(themes[currentThemeIndex]);
            }

            // Cycle to next theme
            currentThemeIndex = (currentThemeIndex + 1) % themes.length;

            // Add new theme class if it exists (not empty string)
            if (themes[currentThemeIndex]) {
                body.classList.add(themes[currentThemeIndex]);
                localStorage.setItem('theme', themes[currentThemeIndex]);
            } else {
                localStorage.removeItem('theme');
            }

            // Update icon
            icon.textContent = icons[currentThemeIndex];
        });
    </script>
</body>
</html>