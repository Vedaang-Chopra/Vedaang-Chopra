<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>"Part 2: Seeing Is the Bottleneck: MOLMO's Image Preprocessing" - Vedaang Chopra</title>
    <link rel="stylesheet" href="https://vedaangchopra.live/theme/css/style.css" />
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <a href="https://vedaangchopra.live/" class="profile-brand">
                    <img src="https://vedaangchopra.live/images/profile.png" alt="Profile" class="profile-circle">
                </a>
                <a href="https://vedaangchopra.live/" class="brand">Home</a>
                <a href="https://vedaangchopra.live/projects.html">Projects</a>
                <a href="/resume.html">Resume</a>
                <a href="/blog.html">Writing</a>
                <a href="/uses.html">Uses</a>
                <button id="theme-toggle" aria-label="Toggle Theme">
                    <span class="icon">‚òÄ</span>
                </button>
            </nav>
        </header>

        <main>
<article>
    <header>
        <h1>"Part 2: Seeing Is the Bottleneck: MOLMO's Image Preprocessing"</h1>
        <div class="meta">
            <span class="date">2026-02-09</span>
        </div>
    </header>
    
    <div class="content">
        <p><strong>Part 2 of a 4-part series on Vision-Language Model design.</strong><br>
<a href="/blog/molmo-part-1">‚Üê Previous</a> | <a href="/blog/molmo-part-3">Next ‚Üí</a></p>
<hr>
<h1>Seeing Is the Bottleneck: MOLMO's Image Preprocessing</h1>
<h2>Why MOLMO's Architecture Is Quietly Radical</h2>
<p>At first glance, MOLMO's architecture looks almost conservative. There is no novel transformer variant, no exotic fusion module, and no end-to-end multimodal pretraining trick that fundamentally alters the standard VLM recipe. This is intentional.</p>
<p>MOLMO's architectural contribution is not about <em>inventing new components</em>, but about <strong>treating known constraints as immovable facts</strong> and designing around them. In particular, it takes seriously a constraint that many VLMs implicitly ignore:</p>
<blockquote>
<p>Vision Transformers are square, resolution-limited models operating on patchified images‚Äîwhile real-world visual reasoning is neither square nor low-resolution.</p>
</blockquote>
<p>Most VLMs implicitly assume that resizing an image to a single fixed resolution is a harmless preprocessing step. MOLMO treats this assumption as false.</p>
<hr>
<h2>The Core Mismatch: ViTs vs. Real Images</h2>
<p>Vision Transformers like ViT-L/14 accept inputs of a fixed resolution (e.g., 336√ó336). This creates an unavoidable trade-off:</p>
<ul>
<li>Resize aggressively ‚Üí preserve global layout, lose fine detail.</li>
<li>Crop aggressively ‚Üí preserve detail, lose context.</li>
</ul>
<p>Most VLMs choose one side of this trade-off implicitly. MOLMO refuses to choose. Instead, it reframes the problem:</p>
<blockquote>
<p>What if the vision encoder sees <em>multiple coherent views</em> of the same image, each optimized for a different level of abstraction?</p>
</blockquote>
<hr>
<h2>Multi-Scale Tiling as a Representation Strategy</h2>
<p>MOLMO's preprocessor produces <strong>two complementary visual representations</strong> from a single image:</p>
<ol>
<li><strong>A low-resolution global view</strong></li>
<li>The entire image resized to 336√ó336.</li>
<li>
<p>Preserves scene-level context, object co-occurrence, and layout.</p>
</li>
<li>
<p><strong>Multiple high-resolution overlapping crops</strong></p>
</li>
<li>Each crop is 336√ó336.</li>
<li>Covers the image on a grid.</li>
<li>Overlaps adjacent crops to avoid boundary artifacts.</li>
</ol>
<p>This is not a data augmentation trick. It is a <strong>deliberate representational decomposition</strong>. Figure 5 from the MOLMO paper illustrates this process:</p>
<p><img alt="Converting an image into tokens. The image is turned into a single low-res and several overlapping high-res crops." src="/images/molmo_tokens_sequence.png"></p>
<p><em>Figure 5: Image-to-token conversion. The original image (top left) produces a low-resolution global view and multiple high-resolution crops (bottom left). Special tokens mark image start, end, and row boundaries.</em></p>
<p>Each crop answers a different question:
* <em>What is happening overall?</em>
* <em>What fine details exist here?</em>
* <em>What text or small objects would be lost otherwise?</em></p>
<hr>
<h2>Why Overlap Matters (More Than It Seems)</h2>
<p>The overlapping region between crops is not incidental. Without overlap, objects near crop boundaries get split, text gets truncated, and spatial continuity breaks. By overlapping crops, MOLMO ensures that <strong>any visually meaningful region appears fully in at least one crop</strong>. This guarantees that the vision encoder never sees "half an object" as its best view.</p>
<p>Figure 3 from the paper demonstrates the difference clearly:</p>
<p><img alt="An image cropped without and with overlap. Overlapping crops ensure that central patches are encoded with neighboring context." src="/images/molmo_overlap_comparison.png"></p>
<p><em>Figure 3: Overlap vs. no-overlap cropping. Highlighted regions show areas used by the LLM. With overlap, the bike's brand name is always fully visible in at least one crop.</em></p>
<p>From a reasoning perspective, this is crucial. The LLM can only reason over <em>complete visual evidence</em>, not fragmented patches.</p>
<hr>
<h2>Padding Is Also a Modeling Choice</h2>
<p>Real images rarely tile perfectly. MOLMO pads edge crops when needed, but does so explicitly:
* Each patch is tagged as real image, partial padding, or full padding.
* Padding-type embeddings tell the model what is <em>absence</em> versus <em>dark pixels</em>.</p>
<p>This avoids a subtle but common failure mode where models confuse black padding with visual content‚Äîparticularly harmful in low-light or nighttime scenes.</p>
<hr>
<h2>The Key Insight</h2>
<p>The key insight here is not multi-scale cropping itself, but what it represents: <strong>visual reasoning is scale-sensitive</strong>. A single resolution cannot support both perception and interpretation. MOLMO treats scale as a <strong>first-class axis of representation</strong>, rather than something the model is expected to infer implicitly.</p>
<p>MOLMO reframes where architectural novelty should live: not necessarily in deeper encoders or larger language models, but in <strong>how visual evidence is preserved, structured, and made accessible to reasoning mechanisms</strong>.</p>
<p>This is why MOLMO is better understood as an architectural <em>correction</em> rather than an architectural <em>innovation</em>. It does not add complexity; it removes implicit assumptions that were never justified.</p>
<hr>
<p><strong>Part 2 of a 4-part series on Vision-Language Model design.</strong><br>
<a href="/blog/molmo-part-1">‚Üê Previous</a> | <a href="/blog/molmo-part-3">Next ‚Üí</a></p>
    </div>
</article>
        </main>

        <footer>
            <div class="footer-content">
                <div class="footer-icons">
                    <a href="https://github.com/Vedaang-Chopra" target="_blank" class="footer-icon-btn" aria-label="GitHub">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    </a>
                    <a href="https://linkedin.com/in/vedaang-chopra/" target="_blank" class="footer-icon-btn" aria-label="LinkedIn">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg>
                    </a>
                    <a href="mailto:vedaangchopra1009@gmail.com" class="footer-icon-btn" aria-label="Email">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg>
                    </a>
                </div>
                <div class="footer-links">
                    <p>&copy; 2026 Vedaang Chopra</p>
                </div>
            </div>
        </footer>
    </div>

    <script>
        const toggleBtn = document.getElementById('theme-toggle');
        const body = document.body;
        const icon = toggleBtn.querySelector('.icon');

        // Theme Definitions
        const themes = ['', 'mint-theme', 'dark-theme', 'sepia-theme'];
        const icons = ['‚òÄ', 'üåø', 'üåô', '‚òï'];

        // Load saved theme
        let currentThemeIndex = 0;
        const savedTheme = localStorage.getItem('theme');
        
        if (savedTheme) {
            const savedIndex = themes.indexOf(savedTheme);
            if (savedIndex !== -1) {
                currentThemeIndex = savedIndex;
                if (themes[currentThemeIndex]) {
                    body.classList.add(themes[currentThemeIndex]);
                }
                icon.textContent = icons[currentThemeIndex];
            }
        }

        toggleBtn.addEventListener('click', () => {
            // Remove current theme class if it exists
            if (themes[currentThemeIndex]) {
                body.classList.remove(themes[currentThemeIndex]);
            }

            // Cycle to next theme
            currentThemeIndex = (currentThemeIndex + 1) % themes.length;

            // Add new theme class if it exists (not empty string)
            if (themes[currentThemeIndex]) {
                body.classList.add(themes[currentThemeIndex]);
                localStorage.setItem('theme', themes[currentThemeIndex]);
            } else {
                localStorage.removeItem('theme');
            }

            // Update icon
            icon.textContent = icons[currentThemeIndex];
        });
    </script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: false });

        document.addEventListener('DOMContentLoaded', () => {
            const mermaidBlocks = document.querySelectorAll('code.language-mermaid, .highlight .mermaid, .codehilite .mermaid');
            mermaidBlocks.forEach(block => {
                const div = document.createElement('div');
                div.className = 'mermaid';
                div.textContent = block.textContent;
                
                // Handle different nesting structures
                let target = block;
                if (block.tagName === 'CODE' && block.parentElement.tagName === 'PRE') {
                    target = block.parentElement;
                    if (target.parentElement.classList.contains('highlight') || target.parentElement.classList.contains('codehilite')) {
                        target = target.parentElement;
                    }
                }
                target.replaceWith(div);
            });

            mermaid.run({
                nodes: document.querySelectorAll('.mermaid')
            });
        });
    </script>
</body>
</html>